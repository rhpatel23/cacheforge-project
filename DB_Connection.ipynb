{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "436e8780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import sqlite3\n",
    "import subprocess\n",
    "import re\n",
    "from pathlib import Path\n",
    "from RAG import *\n",
    "from PromptGenerator import *\n",
    "from collections import defaultdict\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30052ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH       = \"DB/funsearch3.db\"\n",
    "TRACE_PATH    = Path(\"ChampSim_CRC2/traces/mcf_250B.trace.gz\")\n",
    "LIB_PATH      = \"ChampSim_CRC2/lib/config1.a\"\n",
    "INCLUDE_DIR   = \"ChampSim_CRC2/inc\"\n",
    "WARMUP_INST   = \"1000000\"\n",
    "SIM_INST      = \"10000000\"\n",
    "OUT_DIR   = Path(\"ChampSim_CRC2/new_policies\")\n",
    "\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "CSV_PATH = \"policy_stats_mcf.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cab9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_policy(src: Path) -> Path:\n",
    "    \"\"\"g++ <src> -> <src>.out  (always recompiles)\"\"\"\n",
    "    exe = OUT_DIR / (src.stem + \".out\")\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"g++\",\n",
    "            \"-Wall\",\n",
    "            \"-std=c++17\",\n",
    "            f\"-I{INCLUDE_DIR}\",\n",
    "            str(src),\n",
    "            LIB_PATH,\n",
    "            \"-o\",\n",
    "            str(exe),\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n",
    "    return exe\n",
    "\n",
    "\n",
    "def run_policy(exe: Path) -> str:\n",
    "    \"\"\"Execute ChampSim binary and capture stdout.\"\"\"\n",
    "    res = subprocess.run(\n",
    "        [\n",
    "            str(exe),\n",
    "            \"-warmup_instructions\", WARMUP_INST,\n",
    "            \"-simulation_instructions\", SIM_INST,\n",
    "            \"-traces\", str(TRACE_PATH),\n",
    "        ],\n",
    "        check=True,\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "    )\n",
    "    return res.stdout\n",
    "\n",
    "\n",
    "def parse_llc_stats(text: str) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Extract 'LLC TOTAL ACCESS: <A> HIT: <H>' and return (A, H).\n",
    "    Raises if pattern not found.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"LLC TOTAL\\s+ACCESS:\\s+(\\d+)\\s+HIT:\\s+(\\d+)\", text)\n",
    "    if not m:\n",
    "        raise RuntimeError(\"LLC TOTAL line not found in ChampSim output\")\n",
    "    access, hits = map(int, m.groups())\n",
    "    return access, hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dcc279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "workloads = {\n",
    "    \"astar\": {\n",
    "        \"description\": (\n",
    "            \"The A* workload models a pathfinding algorithm commonly used in game AI and robotics. \"\n",
    "            \"It is characterized by deeply nested control-flow, frequent branching, and high rates of speculative execution due to unpredictable decisions in the search space. \"\n",
    "            \"Memory access patterns are moderately sparse with irregular access strides and limited reuse, making it a stress test for branch predictors and instruction-level parallelism. \"\n",
    "            \"Cache-wise, it has a moderate trace size and shows limited temporal locality, challenging replacement policies to avoid pollution from control-dominated paths.\"\n",
    "        ),\n",
    "        \"trace\": \"ChampSim_CRC2/traces/astar_313B.trace.gz\"\n",
    "    },\n",
    "    \"lbm\": {\n",
    "        \"description\": (\n",
    "            \"LBM (Lattice-Boltzmann Method) simulates fluid dynamics by performing stencil-based updates across 3D grids. \"\n",
    "            \"It exhibits dense, regular memory access patterns with high spatial locality but limited temporal reuse. \"\n",
    "            \"Cache pressure is significant due to large working sets and repetitive accesses across neighboring cells, making it ideal for evaluating how well a policy handles spatial locality and prefetching alignment. \"\n",
    "            \"LBM’s deterministic access stride also exposes weaknesses in replacement strategies that fail to retain blocks until their reuse window arrives.\"\n",
    "        ),\n",
    "        \"trace\": \"ChampSim_CRC2/traces/lbm_564B.trace.gz\"\n",
    "    },\n",
    "    \"mcf\": {\n",
    "        \"description\": (\n",
    "            \"The MCF workload solves the Minimum Cost Flow problem using network simplex algorithms. \"\n",
    "            \"It is known for pointer-chasing behavior, deep data dependencies, and highly irregular, sparse memory accesses. \"\n",
    "            \"This leads to poor cache locality and low IPC due to frequent pipeline stalls from memory latency. \"\n",
    "            \"MCF is a classical example of memory-bound workloads and is particularly harsh on cache replacement policies that rely on recency or frequency heuristics. \"\n",
    "            \"Its access patterns are difficult to predict, making it valuable for testing adaptive and learned policies.\"\n",
    "        ),\n",
    "        \"trace\": \"ChampSim_CRC2/traces/mcf_250B.trace.gz\"\n",
    "    },\n",
    "    \"milc\": {\n",
    "        \"description\": (\n",
    "            \"MILC simulates Quantum Chromodynamics (QCD) calculations on 4D space-time lattices, often used in particle physics research. \"\n",
    "            \"The workload includes extensive use of floating-point arithmetic within nested loops, coupled with both regular and irregular memory accesses. \"\n",
    "            \"MILC combines phases of high spatial reuse with intermittent pointer dereferencing and indirect indexing, leading to inconsistent locality characteristics. \"\n",
    "            \"This makes it a strong candidate for evaluating how well a replacement policy can respond to phase changes in workload behavior.\"\n",
    "        ),\n",
    "        \"trace\": \"ChampSim_CRC2/traces/milc_409B.trace.gz\"\n",
    "    },\n",
    "    \"omnetpp\": {\n",
    "        \"description\": (\n",
    "            \"Omnet++ models a discrete-event network simulator, simulating communication protocols with complex object-oriented structures. \"\n",
    "            \"It features heavy dynamic memory allocation, small object usage, and highly unpredictable control flow. \"\n",
    "            \"Its access pattern is dominated by pointer dereferencing and virtual function calls, resulting in low spatial and temporal locality. \"\n",
    "            \"Frequent branching and irregular memory usage make it a demanding workload for branch predictors and cache systems, especially those relying on stable reuse signals.\"\n",
    "        ),\n",
    "        \"trace\": \"ChampSim_CRC2/traces/omnetpp_17B.trace.gz\"\n",
    "    }\n",
    "}\n",
    "\n",
    "policies = {\n",
    "    \"LRU\": {\n",
    "        \"description\": (\n",
    "            \"Least Recently Used (LRU) replacement policy evicts the cache line that has not been accessed for the longest time. \"\n",
    "            \"It assumes temporal locality—recently used data is more likely to be used again. \"\n",
    "            \"This simple stack-based heuristic is hardware-friendly but can perform poorly under non-recurring access patterns or streaming workloads.\"\n",
    "        ),\n",
    "        \"file_path\": \"ChampSim_CRC2/champ_repl_pol/lru.cc\"\n",
    "    },\n",
    "    \"Hawkeye\": {\n",
    "        \"description\": (\n",
    "            \"Hawkeye is a predictive replacement policy that leverages Belady's MIN algorithm as an oracle during training phases. \"\n",
    "            \"It classifies memory accesses as cache-friendly or cache-averse using past reuse behavior. \"\n",
    "            \"Hawkeye tracks the hit/miss patterns of PCs and predicts future reuse, evicting lines unlikely to be reused. \"\n",
    "            \"This learned policy often outperforms heuristics in workloads with high variance in reuse patterns.\"\n",
    "        ),\n",
    "        \"file_path\": \"ChampSim_CRC2/champ_repl_pol/hawkeye_final.cc\"\n",
    "    },\n",
    "    \"Less is More\": {\n",
    "        \"description\": (\n",
    "            \"The Less is More (LIME) policy maintains a smaller but more predictable working set in cache by selectively caching only highly reusable data. \"\n",
    "            \"It introduces filters or confidence thresholds to reduce cache pollution, especially effective in workloads with sparse reuse or high noise. \"\n",
    "            \"By avoiding over-commitment, it reduces thrashing and improves effective cache utilization in irregular access patterns.\"\n",
    "        ),\n",
    "        \"file_path\": \"ChampSim_CRC2/champ_repl_pol/lime.cc\"\n",
    "    },\n",
    "    \"Multiperspective\": {\n",
    "        \"description\": (\n",
    "            \"Multiperspective replacement integrates multiple heuristics—temporal (recency), spatial (block adjacency), and frequency (access counts)—\"\n",
    "            \"to make informed eviction decisions. \"\n",
    "            \"It balances short-term reuse with longer-term utility predictions, offering adaptability across diverse workloads. \"\n",
    "            \"This hybrid strategy is especially useful in mixed compute and memory-intensive applications.\"\n",
    "        ),\n",
    "        \"file_path\": \"ChampSim_CRC2/champ_repl_pol/dancrc2.cc\"\n",
    "    },\n",
    "    \"Reordering-based Cache Replacement\": {\n",
    "        \"description\": (\n",
    "            \"This policy reorders memory accesses to increase temporal locality before they reach the cache. \"\n",
    "            \"By dynamically reshaping the access stream (e.g., via scheduling queues or address clustering), it reduces conflict misses and enhances reuse. \"\n",
    "            \"The effectiveness is tied to how well reordering aligns with the underlying data reuse patterns of the workload.\"\n",
    "        ),\n",
    "        \"file_path\": \"ChampSim_CRC2/champ_repl_pol/red.cc\"\n",
    "    },\n",
    "    \"Ship++\": {\n",
    "        \"description\": (\n",
    "            \"SHiP++ (Signature-based Hit Predictor) is an enhancement over the SHiP policy, which uses PC-based signatures and outcome history to track line usefulness. \"\n",
    "            \"SHiP++ incorporates refined predictors, decay mechanisms, and hybrid reuse classification to better handle pathological cases (e.g., thrashing). \"\n",
    "            \"It provides strong performance across workloads with dynamic and complex reuse patterns.\"\n",
    "        ),\n",
    "        \"file_path\": \"ChampSim_CRC2/champ_repl_pol/ship++.cc\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3504e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_policy(src: Path) -> Path:\n",
    "    \"\"\"g++ <src> -> <src>.out using correct CRC-2 method\"\"\"\n",
    "    policy_name = src.stem\n",
    "    exe_name = f\"{policy_name}.out\"\n",
    "    exe_path = OUT_DIR / exe_name\n",
    "    \n",
    "    original_cwd = os.getcwd()\n",
    "    champsim_dir = Path(\"ChampSim_CRC2\")\n",
    "    \n",
    "    try:\n",
    "        os.chdir(champsim_dir)\n",
    "        \n",
    "        subprocess.run([\n",
    "            \"g++\",\n",
    "            \"-Wall\", \n",
    "            \"--std=c++11\",\n",
    "            \"-o\", exe_name,\n",
    "            str(src.relative_to(champsim_dir)),\n",
    "            \"lib/config1.a\"\n",
    "        ], check=True)\n",
    "        \n",
    "        import shutil\n",
    "        shutil.move(exe_name, str(exe_path))\n",
    "        \n",
    "    finally:\n",
    "        os.chdir(original_cwd)\n",
    "    \n",
    "    return exe_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb700a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'astar': [0.45454223305787467, 0.3573547794394494, 0.38901773944350737, 0.03709567109384967, 0.4110201774653078, 0.33821173935846005], 'lbm': [0.43985783443540666, 0.27289983516244354, 0.32972240516582263, 0.011593643367720617, 0.19358477211349756, 0.2615846099982021], 'mcf': [0.4074020886631043, 0.5087725688923012, 0.5230175409101099, 0.515161598323247, 0.5200312710592792, 0.524743749964974], 'milc': [0.3219114100958022, 0.06456693483565899, 0.23460321368313578, 0.00026430697263517673, 0.14627399581453615, 0.054986712238499026], 'omnetpp': [0.4606533811310401, 0.6753672808393627, 0.6900525496418154, 0.008547620325799737, 0.4621028207407054, 0.698462878241108]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#double-check your results with the following results\n",
    "perf_data={\n",
    "    'astar': [0.45454223305787467, 0.3573547794394494, 0.38901773944350737, 0.03709567109384967, 0.4110201774653078, 0.33821173935846005], \n",
    "    'lbm': [0.43985783443540666, 0.27289983516244354, 0.32972240516582263, 0.011593643367720617, 0.19358477211349756, 0.2615846099982021], \n",
    "    'mcf': [0.4074020886631043, 0.5087725688923012, 0.5230175409101099, 0.515161598323247, 0.5200312710592792, 0.524743749964974], \n",
    "    'milc': [0.3219114100958022, 0.06456693483565899, 0.23460321368313578, 0.00026430697263517673, 0.14627399581453615, 0.054986712238499026],\n",
    "    'omnetpp': [0.4606533811310401, 0.6753672808393627, 0.6900525496418154, 0.008547620325799737, 0.4621028207407054, 0.698462878241108]}\n",
    "\n",
    "performance_data = perf_data  \n",
    "print(performance_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0ac3c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LRU': 0.4168733894766456, 'Hawkeye': 0.37579227983384317, 'Less is More': 0.4332826897688782, 'Multiperspective': 0.11453256801665043, 'Reordering-based Cache Replacement': 0.3466026074386652, 'Ship++': 0.37559793796024865}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Compute the average hit rate (score) per policy\n",
    "policy_hit_rates = defaultdict(list)  # key = policy_name, value = list of hit rates\n",
    "\n",
    "# Populate policy_hit_rates from performance_data\n",
    "for workload_name in workloads:\n",
    "    for i, policy_name in enumerate(policies):\n",
    "        hit_rate = perf_data[workload_name][i]\n",
    "        policy_hit_rates[policy_name].append(hit_rate)\n",
    "\n",
    "# Calculate average score for each policy\n",
    "policy_scores = {\n",
    "    policy_name: sum(hit_rates) / len(hit_rates) if hit_rates else 0.0\n",
    "    for policy_name, hit_rates in policy_hit_rates.items()\n",
    "}\n",
    "\n",
    "print(policy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35680012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database connection (creates file if it doesn't exist)\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Create a cursor\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create the table\n",
    "c.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS experiments (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        workload TEXT NOT NULL,\n",
    "        policy TEXT NOT NULL,\n",
    "        policy_description TEXT NOT NULL,\n",
    "        workload_description TEXT NOT NULL,\n",
    "        cpp_file_path TEXT NOT NULL,\n",
    "        cache_hit_rate REAL NOT NULL,\n",
    "        score REAL NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d348110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully inserted into the funsearch.db database!\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(DB_PATH)\n",
    "c = conn.cursor()\n",
    "\n",
    "for workload_name, wdata in workloads.items():\n",
    "    workload_desc = wdata[\"description\"]\n",
    "    \n",
    "    for i, (policy_name, pdata) in enumerate(policies.items()):\n",
    "        policy_desc = pdata[\"description\"]\n",
    "        cpp_path = pdata[\"file_path\"]\n",
    "\n",
    "        hit_rate = perf_data[workload_name][i]\n",
    "        score = policy_scores[policy_name]  # use the precomputed average score\n",
    "\n",
    "        c.execute('''\n",
    "            INSERT INTO experiments (\n",
    "                workload,\n",
    "                policy,\n",
    "                policy_description,\n",
    "                workload_description,\n",
    "                cpp_file_path,\n",
    "                cache_hit_rate,\n",
    "                score\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            workload_name,\n",
    "            policy_name,\n",
    "            policy_desc,\n",
    "            workload_desc,\n",
    "            cpp_path,\n",
    "            hit_rate,\n",
    "            score\n",
    "        ))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data has been successfully inserted into the funsearch.db database!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b0a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB_PATH)\n",
    "c = conn.cursor()\n",
    "\n",
    "for i, (policy_name, pdata) in enumerate(policies.items()):\n",
    "        policy_desc = pdata[\"description\"]\n",
    "        cpp_path = pdata[\"file_path\"]\n",
    "        score = policy_scores[policy_name]\n",
    "\n",
    "        c.execute('''\n",
    "            INSERT INTO experiments (\n",
    "                workload,\n",
    "                policy,\n",
    "                policy_description,\n",
    "                workload_description,\n",
    "                cpp_file_path,\n",
    "                cache_hit_rate,\n",
    "                score\n",
    "            ) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            \"all\",\n",
    "            policy_name,\n",
    "            policy_desc,\n",
    "            \"\",\n",
    "            cpp_path,\n",
    "            score,\n",
    "            score\n",
    "        ))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3951277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less is More  ---  0.4332826897688782\n",
      "LRU  ---  0.4168733894766456\n",
      "Hawkeye  ---  0.37579227983384317\n",
      "Ship++  ---  0.37559793796024865\n",
      "Reordering-based Cache Replacement  ---  0.3466026074386652\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from RAG import ExperimentRAG\n",
    "from pathlib import Path\n",
    "from RAG import *\n",
    "from PromptGenerator import *\n",
    "\n",
    "DB_PATH= \"DB/funsearch3.db\"\n",
    "\n",
    "WORKLOAD=\"all\"\n",
    "rag = ExperimentRAG(DB_PATH)\n",
    "top2 = rag.get_top_policies_by_score(WORKLOAD, top_n=5)\n",
    "if not top2:\n",
    "    raise RuntimeError(\"No RAG data for workload\")\n",
    "workload_desc = top2[0][\"workload_description\"]\n",
    "\n",
    "print(top2[0]['policy'],\" --- \", top2[0]['score'])\n",
    "print(top2[1]['policy'],\" --- \", top2[1]['score'])\n",
    "print(top2[2]['policy'],\" --- \", top2[2]['score'])\n",
    "print(top2[3]['policy'],\" --- \", top2[3]['score'])\n",
    "print(top2[4]['policy'],\" --- \", top2[4]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e56ad9-46b1-4916-8cb2-a8c8c1fb5312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
